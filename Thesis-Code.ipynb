{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04G6b-qaXB08",
        "outputId": "066fb2ff-fa55-4a4d-ef2c-ff99259e7365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arabic_reshaper in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (0.6.6)\n",
            "Running scenario: Complex_Structure\n",
            "Generating data...\n",
            "A_true:\n",
            " [[1.  0.  0.7 0.7]\n",
            " [0.  1.  0.7 0.7]\n",
            " [0.  0.  1.  0. ]\n",
            " [0.  0.  0.  1. ]\n",
            " [0.  0.  0.  0. ]]\n",
            "Bootstrap stability: repeats=100, k_est=3 ...\n",
            "Selected k: 4\n",
            "Selected k: 4\n",
            "Selected k: 4\n",
            "Selected k: 4\n",
            "Selected k: 4\n",
            "Selected k: 4\n",
            "Selected k: 4\n",
            "Selected k: 4\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "IFA + CF causal pipeline — advanced, CF-based alignment & metrics, bootstrap, Graphviz plotting.\n",
        "- ورودی: B_manual (m x m), M_manual (m x k_true)\n",
        "- خروجی: results JSON, PNG تصاویر گراف واقعی و تخمینی، معیارها چاپ شده\n",
        "\"\"\"\n",
        "\n",
        "!pip install arabic_reshaper python-bidi\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "import tempfile\n",
        "from dataclasses import dataclass, field\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from scipy.fft import fft\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "\n",
        "#!pip install arabic_reshaper python-bidi\n",
        "# ---------------------------\n",
        "# Config dataclasses\n",
        "# ---------------------------\n",
        "@dataclass\n",
        "class SCMConfig:\n",
        "    B: np.ndarray\n",
        "    M: np.ndarray\n",
        "    sigma2: float = 0.05\n",
        "    seed: int = 42\n",
        "\n",
        "@dataclass\n",
        "class IFAConfig:\n",
        "    k_est: int = 8\n",
        "    max_iter: int = 1000\n",
        "    tol: float = 1e-6\n",
        "    reg_latent: float = 1e-3\n",
        "\n",
        "@dataclass\n",
        "class BootstrapConfig:\n",
        "    repeats: int = 40\n",
        "    tau_A: float = 0.12\n",
        "    tau_B: float = 0.06\n",
        "    keep_prob: float = 0.6\n",
        "\n",
        "@dataclass\n",
        "class MOGConfig:\n",
        "          n_components:int= 3,\n",
        "          means_strategy: str= 'spread',  # 'spread', 'clustered', 'asymmetric'\n",
        "          variance_strategy : str= 'moderate',  # 'low', 'moderate', 'high'\n",
        "          weights_strategy: str= 'balanced'  # 'balanced', 'imbalanced'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RunConfig:\n",
        "    n: int = 4000\n",
        "    scm: SCMConfig = None\n",
        "    mog:MOGConfig=field(default_factory=MOGConfig)\n",
        "    ifa: IFAConfig = field(default_factory=IFAConfig)\n",
        "    boot: BootstrapConfig = field(default_factory=BootstrapConfig)\n",
        "    senario: str = \"default\"\n",
        "    outdir: str = \"./ifa_cf_result\"\n",
        "    use_graphviz: bool = True\n",
        "\n",
        "#-------------------------\n",
        "# Funtions for test\n",
        "#-------------------------\n",
        "def run_comprehensive_data_tests():\n",
        "    \"\"\"\n",
        " اجرای تست‌های جامع با شرایط مختلف داده‌سازی\n",
        "    \"\"\"\n",
        "    test_scenarios = [\n",
        "\n",
        "       {\n",
        "            'name': 'Complex_Structure',\n",
        "            'mog_config': {'n_components': 3, 'means_strategy': 'spread',\n",
        "                          'variance_strategy': 'moderate', 'weights_strategy': 'balanced'},\n",
        "            'scale_strategy': 'moderate',\n",
        "            'structure_type': 'hierarchical'\n",
        "        },\n",
        "        {\n",
        "            'name': 'Baseline',\n",
        "            'mog_config': {'n_components': 2, 'means_strategy': 'spread',\n",
        "                          'variance_strategy': 'moderate', 'weights_strategy': 'balanced'},\n",
        "            'scale_strategy': 'moderate',\n",
        "            'structure_type': 'chain'\n",
        "        },\n",
        "        {\n",
        "            'name': 'Strong_Signal',\n",
        "            'mog_config': {'n_components': 3, 'means_strategy': 'spread',\n",
        "                          'variance_strategy': 'low', 'weights_strategy': 'balanced'},\n",
        "            'scale_strategy': 'strong',\n",
        "            'structure_type': 'chain'\n",
        "        },\n",
        "        {\n",
        "            'name': 'Challenging_MoG',\n",
        "            'mog_config': {'n_components': 4, 'means_strategy': 'clustered',\n",
        "                          'variance_strategy': 'high', 'weights_strategy': 'imbalanced'},\n",
        "            'scale_strategy': 'moderate',\n",
        "            'structure_type': 'chain'\n",
        "        }\n",
        "\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for scenario in test_scenarios:\n",
        "        print(f\"Running scenario: {scenario['name']}\")\n",
        "\n",
        "        # تولید ساختار\n",
        "        B, M = generate_different_structures(5, 4, scenario['structure_type'])\n",
        "        B, M = optimize_matrix_scaling(B, M, scenario['scale_strategy'])\n",
        "\n",
        "        mog_snr=scenario['mog_config']\n",
        "\n",
        "        # اجرای pipeline\n",
        "        cfg = RunConfig(\n",
        "            n=10000,\n",
        "            scm=SCMConfig(B=B, M=M, sigma2=4.3, seed=42),\n",
        "            mog = MOGConfig(n_components=mog_snr['n_components'],\n",
        "                            means_strategy=mog_snr['means_strategy'],\n",
        "                            variance_strategy=mog_snr['variance_strategy'],\n",
        "                            weights_strategy=mog_snr['weights_strategy']),\n",
        "            ifa = IFAConfig(k_est=3, max_iter=300, tol=1e-6, reg_latent=1e-4),\n",
        "            boot = BootstrapConfig(repeats=100, tau_A=0.2, tau_B=0.1, keep_prob=0.5),\n",
        "            outdir=f\"./ifa_cf_result/{scenario['name']}\",\n",
        "            senario=scenario['name'],\n",
        "            use_graphviz=True\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            result = run_pipeline_advanced(B, M, cfg)\n",
        "\n",
        "            results[scenario['name']] = result\n",
        "        except Exception as e:\n",
        "            print(f\"Scenario {scenario['name']} failed: {e}\")\n",
        "            results[scenario['name']] = {'error': str(e)}\n",
        "\n",
        "    return results\n",
        "#---------------------------\n",
        "# Generate structure\n",
        "#--------------------------\n",
        "def generate_different_structures(m, k, structure_type='chain'):\n",
        "    \"\"\"\n",
        "    تولید ساختارهای مختلف گرافی برای تست robustness\n",
        "    \"\"\"\n",
        "    if structure_type == 'chain':\n",
        "        # ساختار زنجیره‌ای\n",
        "        B = np.zeros((m, m))\n",
        "        for i in range(m-1):\n",
        "            B[i, i+1] = 0.8\n",
        "        M = np.eye(m, k)\n",
        "\n",
        "    elif structure_type == 'hierarchical' and m>=4:\n",
        "        # ساختار سلسله مراتبی\n",
        "        B = np.zeros((m, m))\n",
        "        # لایه اول به دوم\n",
        "        for i in range(2):\n",
        "            for j in range(2, 4):\n",
        "                B[i,j ] = 0.7\n",
        "        # لایه دوم به سوم\n",
        "        for i in range(2, 4):\n",
        "            for j in range(4, m):\n",
        "                B[i, j] = 0.6\n",
        "\n",
        "        M = np.zeros((m, k))\n",
        "        M[:2, :2] = np.eye(2)\n",
        "        M[2:4, 2:4] = np.eye(2)\n",
        "\n",
        "    elif structure_type == 'random':\n",
        "        # ساختار تصادفی با چگالی کنترل شده\n",
        "        B = np.zeros((m, m))\n",
        "        density = 0.3  # چگالی یال‌ها\n",
        "        indices = np.random.choice(m*m, int(m*m*density), replace=False)\n",
        "        for idx in indices:\n",
        "            i, j = idx // m, idx % m\n",
        "            if i != j:  # جلوگیری از حلقه خودی\n",
        "                B[j, i] = np.random.uniform(0.5, 0.9)\n",
        "\n",
        "        M = np.random.randn(m, k) * 0.5\n",
        "        M[np.abs(M) < 0.3] = 0  # ایجاد پراکندگی\n",
        "\n",
        "    return B, M\n",
        "\n",
        "#---------------------------\n",
        "# Align Column\n",
        "#---------------------------\n",
        "def align_columns(A_ref, A_b):\n",
        "    \"\"\"\n",
        "    A_ref : مرجع (m x k)\n",
        "    A_b   : ماتریس تخمین زده شده از bootstrap (m x k)\n",
        "    خروجی: A_b بعد از permutation + sign alignment\n",
        "    \"\"\"\n",
        "    k = A_ref.shape[1]\n",
        "\n",
        "    # --- مرحله 1: محاسبه similarity (اینجا از |corr| استفاده می‌کنیم) ---\n",
        "    sim = np.abs(np.corrcoef(A_ref.T, A_b.T)[:k, k:])\n",
        "\n",
        "    # --- مرحله 2: Hungarian برای پیدا کردن بهترین perm ---\n",
        "    row_ind, col_ind = linear_sum_assignment(-sim)\n",
        "\n",
        "    # --- مرحله 3: اعمال perm روی ستون‌های A_b ---\n",
        "    A_perm = A_b[:, col_ind]\n",
        "\n",
        "    # --- مرحله 4: sign alignment ---\n",
        "    signs = np.sign(np.sum(A_ref * A_perm, axis=0))\n",
        "    A_aligned = A_perm * signs\n",
        "\n",
        "    return A_aligned\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------\n",
        "# sign alignment\n",
        "#-----------------------------\n",
        "# --- sign alignment to a stable reference across bootstraps ---\n",
        "def _col_ref_signs(A):\n",
        "    # return sign = +1 or -1 for each column based on largest-abs entry\n",
        "    k = A.shape[1]\n",
        "    signs = np.ones(k)\n",
        "    for j in range(k):\n",
        "        idx = np.argmax(np.abs(A[:, j]))\n",
        "        s = np.sign(A[idx, j])\n",
        "        if s == 0: s = 1.0\n",
        "        signs[j] = s\n",
        "    return signs\n",
        "\n",
        "# final sign correction relative to A_true (if available)\n",
        "def final_sign_correction(A_est, M_est, A_ref):\n",
        "    A_corr = A_est.copy()\n",
        "    M_corr = M_est.copy()\n",
        "    k = A_est.shape[1]\n",
        "    for j in range(k):\n",
        "        # if A_ref exists and matches dimension\n",
        "        if A_ref is not None and A_ref.shape[1] > j:\n",
        "            dot = np.dot(A_corr[:, j], A_ref[:, j])\n",
        "            if dot < 0:\n",
        "                A_corr[:, j] *= -1.0\n",
        "                M_corr[:, j] *= -1.0\n",
        "        else:\n",
        "            # fallback: ensure max-abs entry positive\n",
        "            idx = np.argmax(np.abs(A_corr[:, j]))\n",
        "            if A_corr[idx, j] < 0:\n",
        "                A_corr[:, j] *= -1.0\n",
        "                M_corr[:, j] *= -1.0\n",
        "    return A_corr, M_corr\n",
        "\n",
        "\n",
        "def normalize_cols(A):\n",
        "    \"\"\"\n",
        "    Normalize columns of matrix A to unit L2 norm.\n",
        "    \"\"\"\n",
        "    A_norm = A.copy()\n",
        "    col_norms = np.linalg.norm(A_norm, axis=0)\n",
        "    # avoid division by zero\n",
        "    col_norms[col_norms == 0] = 1.0\n",
        "    A_norm /= col_norms\n",
        "    return A_norm\n",
        "#----------------------------\n",
        "#  Optimize B,M\n",
        "#----------------------------\n",
        "def optimize_matrix_scaling(B, M, scale_strategy='moderate'):\n",
        "    \"\"\"\n",
        "    بهینه‌سازی مقیاس ماتریس‌های B و M برای بهبود شناسایی\n",
        "    \"\"\"\n",
        "    B_opt = B.copy()\n",
        "    M_opt = M.copy()\n",
        "\n",
        "    if scale_strategy == 'strong':\n",
        "        # تقویت سیگنال برای شناسایی بهتر\n",
        "        B_opt = B_opt * 1.5\n",
        "        M_opt = M_opt * 1.2\n",
        "    elif scale_strategy == 'moderate':\n",
        "        # مقیاس متوسط (پیش‌فرض)\n",
        "        pass\n",
        "    elif scale_strategy == 'weak':\n",
        "        # تضعیف سیگنال برای تست robustness\n",
        "        B_opt = B_opt * 0.7\n",
        "        M_opt = M_opt * 0.8\n",
        "\n",
        "    # اطمینان از اینکه ماتریس B پایدار است\n",
        "    eigenvalues = np.linalg.eigvals(B_opt)\n",
        "    if np.any(np.abs(eigenvalues) >= 1):\n",
        "        # مقیاس‌دهی برای اطمینان از پایداری\n",
        "        scale_factor = 0.9 / np.max(np.abs(eigenvalues))\n",
        "        B_opt = B_opt * scale_factor\n",
        "\n",
        "    return B_opt, M_opt\n",
        "# ---------------------------\n",
        "# 1) Generate data (SCM-MOG)\n",
        "# ---------------------------\n",
        "\n",
        "def generate_data(B, M, n=4000, sigma2=0.05, seed=0, mog_config=None):\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    m, k = M.shape\n",
        "\n",
        "    # تنظیم پارامترهای MoG بر اساس استراتژی\n",
        "    if mog_config.means_strategy == 'spread':\n",
        "        mog_means = np.linspace(-2.5, 2.5, mog_config.n_components)\n",
        "    elif mog_config.means_strategy == 'clustered':\n",
        "        mog_means = np.linspace(-1.0, 1.0, mog_config.n_components)\n",
        "    else:  # asymmetric\n",
        "        mog_means = np.linspace(-1.5, 2.0, mog_config.n_components)\n",
        "\n",
        "    if mog_config.variance_strategy == 'low':\n",
        "        mog_vars = 0.1 * np.ones(mog_config.n_components)\n",
        "    elif mog_config.variance_strategy == 'moderate':\n",
        "        mog_vars = 0.3 * np.ones(mog_config.n_components)\n",
        "    else:  # high\n",
        "        mog_vars = 0.5 * np.ones(mog_config.n_components)\n",
        "\n",
        "    if mog_config.weights_strategy == 'balanced':\n",
        "        mog_weights = np.ones(mog_config.n_components) / mog_config.n_components\n",
        "    else:  # imbalanced\n",
        "        mog_weights = rng.dirichlet(np.ones(mog_config.n_components) * 0.5)\n",
        "        mog_weights = mog_weights / mog_weights.sum()\n",
        "\n",
        "    # تولید داده\n",
        "    H = np.linalg.inv(np.eye(m) - B)\n",
        "    C = mog_config.n_components\n",
        "    Q = np.zeros((k, n))\n",
        "\n",
        "    for i in range(k):\n",
        "        comps = rng.choice(C, size=n, p=mog_weights)\n",
        "        for c in range(C):\n",
        "            mask = (comps == c)\n",
        "            if mask.sum() > 0:\n",
        "                Q[i, mask] = rng.normal(loc=mog_means[c],\n",
        "                                       scale=np.sqrt(mog_vars[c]),\n",
        "                                       size=mask.sum())\n",
        "\n",
        "    E = rng.normal(0.0, np.sqrt(sigma2), size=(m, n))\n",
        "    X = H @ (M @ Q + E)\n",
        "\n",
        "    return X, Q, H\n",
        "\n",
        "\n",
        "#---------------------------\n",
        "# Learn\n",
        "#---------------------------\n",
        "\n",
        "# VB-IFA (Attias-like) — full, practical implementation for model selection by ELBO\n",
        "import numpy as np\n",
        "from scipy.linalg import solve, pinv\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def _safe_log(x):\n",
        "    return np.log(np.maximum(x, 1e-300))\n",
        "\n",
        "def _normalize_columns(A):\n",
        "    norms = np.linalg.norm(A, axis=0) + 1e-12\n",
        "    return A / norms, norms\n",
        "\n",
        "def _init_mixture_params(k, R=3, rng=None):\n",
        "    # initialize mixture params per latent: weights, means, variances\n",
        "    if rng is None: rng = np.random.default_rng(0)\n",
        "    pis = np.ones((k, R)) / R\n",
        "    mus = rng.normal(0, 1.0, size=(k, R))\n",
        "    vars_ = np.ones((k, R)) * 1.0\n",
        "    return pis, mus, vars_\n",
        "\n",
        "def _compute_posterior_S(X, A, sigma2, pis, mus, vars_):\n",
        "    # compute q(S) approx as Gaussian N(S_mean, S_vardiag) assuming factorized across latents\n",
        "    # This is an approximation: we use diagonal posterior covariances for speed (common in VB-IFA practical)\n",
        "    # Returns S_mean (k x n), S_var (k x n), and per-latent posterior precision diag entries (k,)\n",
        "    m, n = X.shape\n",
        "    k = A.shape[1]\n",
        "    # compute Sigma_s_approx diagonal: diag = 1 / (alpha_j + (A_j^T A_j) / sigma2)\n",
        "    # but alpha_j will be computed from mixture responsibilities below; here we use expected precision per latent:\n",
        "    # we'll compute responsibilities given a prior guess of S_mean (iterate)\n",
        "    # initialize: simple least squares to get S_mean\n",
        "    S_mean = np.linalg.pinv(A) @ X  # k x n\n",
        "    # We'll compute S_var diag from A and sigma2 using posterior formula for factor analysis with diag approx\n",
        "    A2sum = np.sum(A**2, axis=0)  # shape (k,)\n",
        "    S_var_diag = (sigma2) / (A2sum[:, None] + 1e-12)  # k x 1 -> k x n after tile\n",
        "    S_var = np.tile(np.maximum(S_var_diag, 1e-12), (1, n))\n",
        "    return S_mean, S_var\n",
        "\n",
        "def _update_mixture_responsibilities(S_mean, S_var, pis, mus, vars_):\n",
        "    # S_mean: k x n, S_var: k x n\n",
        "    k, n = S_mean.shape\n",
        "    R = pis.shape[1]\n",
        "    resp = np.zeros((k, R, n))\n",
        "    # For each latent j, for each component r, responsibility ~ pi_jr * N(s | mu_jr, var_jr + S_var_jn)\n",
        "    for j in range(k):\n",
        "        for r in range(R):\n",
        "            var_effect = vars_[j, r] + S_var[j, :]\n",
        "            # gaussian log-prob:\n",
        "            logp = -0.5 * (_safe_log(2 * np.pi * var_effect) + ((S_mean[j, :] - mus[j, r])**2) / (var_effect))\n",
        "            resp[j, r, :] = _safe_log(pis[j, r]) + logp\n",
        "        # normalize in log-space over r\n",
        "        # subtract max for stability\n",
        "        mx = np.max(resp[j, :, :], axis=0)\n",
        "        resp[j, :, :] = np.exp(resp[j, :, :] - mx[None, :])\n",
        "        sumr = np.sum(resp[j, :, :], axis=0) + 1e-300\n",
        "        resp[j, :, :] = resp[j, :, :] / sumr[None, :]\n",
        "    return resp  # shape (k, R, n)\n",
        "\n",
        "def _update_mixture_params_from_resp(S_mean, S_var, resp):\n",
        "    # resp: k x R x n\n",
        "    k, R, n = resp.shape\n",
        "    pis = np.zeros((k, R))\n",
        "    mus = np.zeros((k, R))\n",
        "    vars_ = np.zeros((k, R))\n",
        "    for j in range(k):\n",
        "        Njr = np.sum(resp[j, :, :], axis=1) + 1e-12  # R\n",
        "        pis[j, :] = Njr / np.sum(Njr)\n",
        "        # means: weighted average of posterior means\n",
        "        for r in range(R):\n",
        "            numer = np.sum(resp[j, r, :] * S_mean[j, :])\n",
        "            mu_r = numer / Njr[r]\n",
        "            mus[j, r] = mu_r\n",
        "            # var: weighted of (S_var + (S_mean - mu)^2)\n",
        "            sq = np.sum(resp[j, r, :] * (S_var[j, :] + (S_mean[j, :] - mu_r)**2))\n",
        "            vars_[j, r] = sq / Njr[r]\n",
        "            vars_[j, r] = max(vars_[j, r], 1e-8)\n",
        "    return pis, mus, vars_\n",
        "\n",
        "def _compute_elbo(X, A, sigma2, S_mean, S_var, resp, pis, mus, vars_):\n",
        "    # Approximate ELBO = E_q[log p(X|S,A)] + E_q[log p(S|z)] + E_q[log p(z)] - E_q[log q(S)] - E_q[log q(z)]\n",
        "    # We'll compute terms in a tractable approximate form.\n",
        "    m, n = X.shape\n",
        "    k = A.shape[1]\n",
        "    R = pis.shape[1]\n",
        "\n",
        "    # 1) E_q[log p(X|S,A)] : Gaussian likelihood with noise sigma2\n",
        "    # = -0.5 * mn * log(2πσ2) - (1/(2σ2)) * E_q[||X - A S||^2]\n",
        "    recon_mean = A @ S_mean  # m x n\n",
        "    # E||X - A S||^2 = ||X - A S_mean||^2 + sum_j sum_n A[:,j]^2 * S_var[j,n]\n",
        "    term1 = np.sum((X - recon_mean)**2)\n",
        "    term1 += np.sum((A**2) @ S_var)  # A**2: m x k ; S_var: k x n -> (m x n) summed\n",
        "    E_log_like = -0.5 * m * n * np.log(2 * np.pi * sigma2) - 0.5 * term1 / sigma2\n",
        "\n",
        "    # 2) E_q[log p(S|z)] where p(s_j | z_j=r) = N(mu_jr, var_jr)\n",
        "    # E over q(s,z): sum_jr sum_n r_jrn * E_{q(s|.)}[log N(s_jn | mu_jr, var_jr)]\n",
        "    E_log_pS = 0.0\n",
        "    for j in range(k):\n",
        "        for r in range(R):\n",
        "            var_r = vars_[j, r]\n",
        "            mu_r = mus[j, r]\n",
        "            # expectation of quadratic term:\n",
        "            # E[(s - mu)^2] = S_var[j,:] + (S_mean[j,:] - mu_r)^2\n",
        "            quad = S_var[j, :] + (S_mean[j, :] - mu_r)**2\n",
        "            logN = -0.5 * (_safe_log(2 * np.pi * var_r) + quad / var_r)\n",
        "            E_log_pS += np.sum(resp[j, r, :] * logN)\n",
        "\n",
        "    # 3) E_q[log p(z)] = sum_jr sum_n r_jrn * log(pi_jr)\n",
        "    E_log_pz = np.sum(resp * _safe_log(pis)[:, :, None])\n",
        "\n",
        "    # 4) - E_q[log q(S)] : q(S) is Gaussian with diagonal cov per latent per sample\n",
        "    # Entropy of Gaussian with variance v: 0.5 * log(2πe v)\n",
        "    ent_S = 0.5 * np.sum(_safe_log(2 * np.pi * np.e * S_var))\n",
        "\n",
        "    # 5) - E_q[log q(z)] : categorical per latent per sample\n",
        "    # = - sum_jn sum_r r_jrn * log r_jrn\n",
        "    ent_z = - np.sum(resp * _safe_log(resp))\n",
        "\n",
        "    elbo = E_log_like + E_log_pS + E_log_pz + ent_S + ent_z\n",
        "    return float(elbo), dict(E_log_like=E_log_like, E_log_pS=E_log_pS, E_log_pz=E_log_pz, ent_S=ent_S, ent_z=ent_z)\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "def learn_ifa_vb_full_with_ard(X, k_candidates, R=3, max_iter=500, tol=1e-6,\n",
        "                              sigma2_init=None, rng_seed=0, verbose=False,\n",
        "                              init_from_pca=True,\n",
        "                              # ARD hyperparams:\n",
        "                              a0=1e-6, b0=1e-6,    # weak gamma prior on alpha\n",
        "                              ard_prune_thresh=1e6, # if alpha_j > thresh -> inactive\n",
        "                              norm_prune_thresh=1e-6 # or if ||A_j|| < thresh -> inactive\n",
        "                             ):\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "    m, n = X.shape\n",
        "    if isinstance(k_candidates, int):\n",
        "        k_candidates = [k_candidates]\n",
        "    k_candidates = sorted(list(k_candidates))\n",
        "    if sigma2_init is None:\n",
        "        sigma2_init = max(1e-8, np.var(X) * 0.01)\n",
        "\n",
        "    all_results = {}\n",
        "    best_elbo = -np.inf\n",
        "    best_result = None\n",
        "\n",
        "    for k in k_candidates:\n",
        "        if verbose:\n",
        "            print(f\"\\n--- VB-IFA+ARD: trying k={k} ---\")\n",
        "        # init A\n",
        "        if init_from_pca:\n",
        "            U, Sdiag, Vt = np.linalg.svd(X / np.sqrt(n), full_matrices=False)\n",
        "            A = np.zeros((m, k))\n",
        "            take = min(U.shape[1], k)\n",
        "            A[:, :take] = U[:, :take] * (Sdiag[:take])\n",
        "            if k > take:\n",
        "                A[:, take:] = rng.normal(0, 0.01, size=(m, k - take))\n",
        "        else:\n",
        "            A = rng.normal(0, 0.01, size=(m, k))\n",
        "        A, _ = _normalize_columns(A)\n",
        "\n",
        "        # init ARD alphas (precision for each column)\n",
        "        alpha = np.ones(k) * 1e-2\n",
        "\n",
        "        # mixture params\n",
        "        pis, mus, vars_ = _init_mixture_params(k, R=R, rng=rng)\n",
        "        sigma2 = float(sigma2_init)\n",
        "\n",
        "        # initial S posterior\n",
        "        S_mean, S_var = _compute_posterior_S(X, A, sigma2, pis, mus, vars_)\n",
        "        resp = _update_mixture_responsibilities(S_mean, S_var, pis, mus, vars_)\n",
        "        pis, mus, vars_ = _update_mixture_params_from_resp(S_mean, S_var, resp)\n",
        "\n",
        "        elbo_trace = []\n",
        "        for it in range(max_iter):\n",
        "            # E-step (like before)\n",
        "            k_, n_ = S_mean.shape\n",
        "            precision_prior = np.zeros((k_, n_))\n",
        "            for j in range(k_):\n",
        "                precision_prior[j, :] = np.sum(resp[j, :, :] / (vars_[j, :, None] + 1e-12), axis=0)\n",
        "\n",
        "            A_col_sqsum = np.sum(A**2, axis=0)\n",
        "            denom = precision_prior + (A_col_sqsum[:, None] / (sigma2 + 1e-12))\n",
        "            S_var = 1.0 / (denom + 1e-12)\n",
        "\n",
        "            AtX = A.T @ X\n",
        "            prior_num = np.zeros_like(S_mean)\n",
        "            for j in range(k_):\n",
        "                num = np.zeros(n_)\n",
        "                for r in range(resp.shape[1]):\n",
        "                    num += resp[j, r, :] * (mus[j, r] / (vars_[j, r] + 1e-12))\n",
        "                prior_num[j, :] = num\n",
        "\n",
        "            S_mean = S_var * (AtX / (sigma2 + 1e-12) + prior_num)\n",
        "\n",
        "            # M-step with ARD prior on A: prior p(A_j) = N(0, alpha_j^{-1} I_m)\n",
        "            ESS = S_mean @ S_mean.T + np.diag(np.sum(S_var, axis=1))\n",
        "            XS_T = X @ S_mean.T\n",
        "\n",
        "            # regularize ESS with sigma2 * diag(alpha)\n",
        "            ESS_reg = ESS + sigma2 * np.diag(alpha + 1e-12)\n",
        "            A_new = XS_T @ np.linalg.inv(ESS_reg + 1e-8 * np.eye(k_))\n",
        "            A_new, _ = _normalize_columns(A_new)  # renormalize to avoid scale ambiguity\n",
        "\n",
        "            # update sigma2 (as before)\n",
        "            recon_mean = A_new @ S_mean\n",
        "            term_recon = np.sum((X - recon_mean)**2) + np.sum((A_new**2) @ S_var)\n",
        "            sigma2_new = max(1e-12, term_recon / (m * n))\n",
        "\n",
        "            # update mixture resp/params\n",
        "            resp = _update_mixture_responsibilities(S_mean, S_var, pis, mus, vars_)\n",
        "            pis, mus, vars_ = _update_mixture_params_from_resp(S_mean, S_var, resp)\n",
        "\n",
        "            # update ARD alpha with Gamma(a0,b0) hyperprior:\n",
        "            # posterior estimate (MAP / moment) for alpha_j:\n",
        "            # alpha_j = (m/2 + a0) / (0.5 * sum_i A_ij^2 + b0)\n",
        "            sqnorms = 0.5 * np.sum(A_new**2, axis=0)  # 0.5 * ||A_j||^2\n",
        "            alpha = (m / 2.0 + a0) / (sqnorms + b0 + 1e-12)\n",
        "\n",
        "            # assign\n",
        "            A = A_new\n",
        "            sigma2 = sigma2_new\n",
        "\n",
        "            # compute ELBO (we can extend compute to include log p(A|alpha) - log q(alpha) if desired)\n",
        "            elbo, _ = _compute_elbo(X, A, sigma2, S_mean, S_var, resp, pis, mus, vars_)\n",
        "            # add ARD prior contribution approx: -0.5 * sum_j alpha_j ||A_j||^2 + (a0-1)log alpha - b0 alpha  (we'll add only the quadratic term for stability)\n",
        "            ard_quadratic = -0.5 * np.sum(alpha * np.sum(A**2, axis=0))\n",
        "            elbo += ard_quadratic\n",
        "\n",
        "            elbo_trace.append(elbo)\n",
        "            if verbose and (it % 20 == 0 or it == max_iter-1):\n",
        "                active = np.sum((alpha < ard_prune_thresh) & (np.linalg.norm(A, axis=0) > norm_prune_thresh))\n",
        "                print(f\"k={k} it={it} ELBO={elbo:.4f} sigma2={sigma2:.4e} active_factors={active}\")\n",
        "\n",
        "            if it > 2:\n",
        "                rel = abs(elbo_trace[-1] - elbo_trace[-2]) / (abs(elbo_trace[-2]) + 1e-12)\n",
        "                if rel < tol:\n",
        "                    if verbose:\n",
        "                        print(f\"k={k} converged it={it} rel_change={rel:.3e}\")\n",
        "                    break\n",
        "\n",
        "        # count effective factors\n",
        "        active_mask = (alpha < ard_prune_thresh) & (np.linalg.norm(A, axis=0) > norm_prune_thresh)\n",
        "        effective_k = int(np.sum(active_mask))\n",
        "        result = {\n",
        "            \"A\": A,\n",
        "            \"S_mean\": S_mean,\n",
        "            \"S_var\": S_var,\n",
        "            \"pis\": pis,\n",
        "            \"mus\": mus,\n",
        "            \"vars\": vars_,\n",
        "            \"sigma2\": sigma2,\n",
        "            \"alpha\": alpha,\n",
        "            \"active_mask\": active_mask,\n",
        "            \"effective_k\": effective_k,\n",
        "            \"elbo_trace\": np.array(elbo_trace),\n",
        "            \"elbo_final\": float(elbo_trace[-1]) if len(elbo_trace) else -np.inf,\n",
        "            \"k\": k\n",
        "        }\n",
        "        all_results[k] = result\n",
        "        if result[\"elbo_final\"] > best_elbo:\n",
        "            best_elbo = result[\"elbo_final\"]\n",
        "            best_result = result\n",
        "        if verbose:\n",
        "            print(f\"Finished k={k} ELBO_final={result['elbo_final']:.4f} effective_k={effective_k}\")\n",
        "\n",
        "    return best_result, all_results\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# estimate B via row-wise Ridge\n",
        "# ---------------------------\n",
        "def estimate_B_ridge(X, alpha=5e-2):\n",
        "    m, n = X.shape\n",
        "    B_hat = np.zeros((m, m))\n",
        "    for i in range(m):\n",
        "        idx = np.arange(m) != i\n",
        "        Xp = X[idx, :]\n",
        "        y = X[i, :]\n",
        "        G = Xp @ Xp.T + alpha * np.eye(m-1)\n",
        "        beta = np.linalg.solve(G, Xp @ y)\n",
        "        B_hat[i, idx] = beta\n",
        "    return B_hat\n",
        "\n",
        "# ---------------------------\n",
        "#  CF tools: empirical CF and distance\n",
        "# ---------------------------\n",
        "def empirical_cf_1d(z, tgrid):\n",
        "    # z: samples (n,)\n",
        "    # returns φ(t) for all tgrid shape (len(tgrid),)\n",
        "    return np.mean(np.exp(1j * np.outer(tgrid, z)), axis=1)\n",
        "\n",
        "def empirical_cf_multivariate(samples, tgrid):\n",
        "     return np.mean(np.exp(1j * (tgrid @ samples)), axis=1)\n",
        "\n",
        "def cf_distance(X_true, X_est, m_grid=200, seed=0):\n",
        "    # X_true, X_est: (d x n)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    d, n = X_true.shape\n",
        "    # sample t vectors from isotropic normal\n",
        "    tgrid = rng.normal(0, 1, size=(m_grid, d))\n",
        "    phi_true = empirical_cf_multivariate(X_true, tgrid)\n",
        "    phi_est = empirical_cf_multivariate(X_est, tgrid)\n",
        "    dist = np.mean(np.abs(phi_true - phi_est)**2).real\n",
        "    return float(dist)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) CF-based alignment (empirical CF per latent) + Hungarian\n",
        "#    Align estimated S_est rows to Q_true rows\n",
        "# ---------------------------\n",
        "def empirical_cf_vector(z, tgrid):\n",
        "    # z shape (n,)\n",
        "    return np.exp(1j * np.outer(tgrid, z)).mean(axis=1)\n",
        "\n",
        "def cf_alignment(Q_true, S_est, tgrid=None):\n",
        "    # Q_true: k_true x n ; S_est: k_est x n\n",
        "    if tgrid is None:\n",
        "        tgrid = np.linspace(-3, 3, 121)\n",
        "    k_true, n = Q_true.shape\n",
        "    k_est, n2 = S_est.shape\n",
        "    assert n == n2\n",
        "    cf_true = [empirical_cf_vector(Q_true[i], tgrid) for i in range(k_true)]   # k_true x T\n",
        "    cf_est = [empirical_cf_vector(S_est[j], tgrid) for j in range(k_est)]      # k_est x T\n",
        "    C = np.zeros((k_true, k_est))\n",
        "    for i in range(k_true):\n",
        "        for j in range(k_est):\n",
        "            diff = cf_true[i] - cf_est[j]\n",
        "            C[i, j] = np.sum(np.abs(diff)**2)\n",
        "    row, col = linear_sum_assignment(C)\n",
        "    perm = col  # perm[i] = index in est matched to true i\n",
        "    # sign correction by corr\n",
        "    signs = np.ones(k_true)\n",
        "    for i in range(k_true):\n",
        "        j = perm[i]\n",
        "        # real correlation (use real parts)\n",
        "        corr = np.corrcoef(Q_true[i].real, S_est[j].real)[0,1]\n",
        "        signs[i] = np.sign(corr) if not np.isnan(corr) else 1.0\n",
        "    return perm, signs\n",
        "\n",
        "# ---------------------------\n",
        "#  Align A_est columns to A_true (via CF alignment on S_est)\n",
        "# ---------------------------\n",
        "def align_A_via_CF(A_est, X, Q_true, tgrid=None):\n",
        "    # S_est = pinv(A_est) @ X\n",
        "    S_est = np.linalg.pinv(A_est) @ X   # k_est x n\n",
        "    perm, signs = cf_alignment(Q_true, S_est, tgrid=tgrid)\n",
        "    m, k_est = A_est.shape\n",
        "    k_true = Q_true.shape[0]\n",
        "    A_aligned = np.zeros((m, k_true))\n",
        "    for i in range(k_true):\n",
        "        j = perm[i]\n",
        "        A_aligned[:, i] = signs[i] * A_est[:, j]\n",
        "        S_est[j, :] *= signs[i]\n",
        "    return A_aligned, perm, signs, S_est\n",
        "\n",
        "# ---------------------------\n",
        "#  Bootstrap stability (fit A and B on bootstrap samples)\n",
        "# ---------------------------\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def bootstrap_stability(X, k_est, repeats=40, tau_A=0.12, tau_B=0.06, seed=0, sigma2=0, alpha_B=1e-2):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    m, n = X.shape\n",
        "    k_target = k_est if isinstance(k_est, int) else (int(k_est[0]) if hasattr(k_est, '__iter__') else int(k_est))\n",
        "\n",
        "    A_stack = np.full((m, k_target, repeats), np.nan)\n",
        "    B_stack = np.full((m, m, repeats), np.nan)\n",
        "\n",
        "    ref_perm = None\n",
        "    ref_signs = None\n",
        "\n",
        "    for b in range(repeats):\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        Xb = X[:, idx]\n",
        "\n",
        "        try:\n",
        "            k_candidates = [2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "            # ---------- فراخوانی تابع یادگیری IFA ----------\n",
        "            best, all_res = learn_ifa_vb_full_with_ard(\n",
        "                Xb,\n",
        "                k_candidates,\n",
        "                R=3,\n",
        "                max_iter=500,\n",
        "                tol=1e-6,\n",
        "                sigma2_init=sigma2,\n",
        "                rng_seed=seed+b,\n",
        "                verbose=False,\n",
        "                init_from_pca=True,\n",
        "                a0=1e-6,\n",
        "                b0=1e-6,\n",
        "                ard_prune_thresh=1e3,\n",
        "                norm_prune_thresh=1e-3\n",
        "            )\n",
        "\n",
        "            print(\"Selected k:\", best['k'])\n",
        "            k_b = best['k']\n",
        "            A_b = best['A']\n",
        "            S_b = best['S_mean']\n",
        "\n",
        "            if A_b is None:\n",
        "                print(f\"learn_ifa returned None at bootstrap {b}, skipping.\")\n",
        "                continue\n",
        "\n",
        "            # pad/truncate A_b to k_target\n",
        "            A_tmp = np.zeros((m, k_target))\n",
        "            kk = min(A_b.shape[1], k_target)\n",
        "            A_tmp[:, :kk] = A_b[:, :kk]\n",
        "            A_b = A_tmp\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"learn_ifa failed on bootstrap {b}: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            B_b = estimate_B_ridge(Xb, alpha=alpha_B)\n",
        "        except Exception as e:\n",
        "            print(f\"estimate_B_ridge failed on bootstrap {b}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # ---------- اصلاح permutation و sign ----------\n",
        "        if ref_perm is None:\n",
        "            # اولین bootstrap موفق -> تنظیم reference\n",
        "            ref_perm = np.arange(A_b.shape[1])\n",
        "            ref_signs = _col_ref_signs(A_b)\n",
        "        else:\n",
        "            # similarity matrix بین ستون‌ها (cosine similarity امن)\n",
        "            sim = np.abs(cosine_similarity(A_stack[:, ref_perm, 0].T, A_b.T))\n",
        "            sim = np.nan_to_num(sim, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "            # Hungarian algorithm برای بهترین permutation\n",
        "            row_ind, col_ind = linear_sum_assignment(-sim)\n",
        "            A_b = A_b[:, col_ind]  # permute columns\n",
        "\n",
        "            # sign alignment\n",
        "            col_signs = _col_ref_signs(A_b)\n",
        "            flip = (col_signs != ref_signs)\n",
        "            for j in range(A_b.shape[1]):\n",
        "                if flip[j]:\n",
        "                    A_b[:, j] *= -1.0\n",
        "\n",
        "        # ---------- ذخیره در stack ----------\n",
        "        A_stack[:, :, b] = A_b\n",
        "        B_stack[:, :, b] = B_b\n",
        "\n",
        "    # compute probabilities ignoring nans\n",
        "    A_prob = np.nanmean(np.abs(A_stack) > tau_A, axis=2)\n",
        "    B_prob = np.nanmean(np.abs(B_stack) > tau_B, axis=2)\n",
        "    A_median = np.nanmedian(A_stack, axis=2)\n",
        "    B_median = np.nanmedian(B_stack, axis=2)\n",
        "\n",
        "    return A_prob, A_median, B_prob, B_median\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------\n",
        "# 9) Purn\n",
        "#--------------------------------\n",
        "\n",
        "\n",
        "\n",
        "def optimal_topo_order_by_dp(Bw):\n",
        "    \"\"\"\n",
        "    ترتیب بهینه‌ی DAG با DP روی زیرمجموعه‌ها (دقیق)\n",
        "    Bw: ماتریس وزن (m x m). وزن یال j->i همان Bw[i,j].\n",
        "    برمی‌گرداند: order (لیست اندیس‌ها از زود به دیر)\n",
        "    \"\"\"\n",
        "    m = Bw.shape[0]\n",
        "    # dp[mask] = بیشترین وزن قابل کسب برای هر زیرمجموعه S با فرض اینکه ترتیب فقط روی S تعریف شود\n",
        "    N = 1 << m\n",
        "    dp = np.full(N, -np.inf, dtype=float)\n",
        "    parent = np.full((N, m), -1, dtype=int)  # برای بازسازی: چه گرهی آخرِ S بوده\n",
        "    dp[0] = 0.0\n",
        "\n",
        "    # پیش‌محاسبه‌ی مجموع وزن یال های u->v که وقتی v آخرِ S قرار گیرد افزوده می‌شود\n",
        "    # اگر v را به عنوان آخرینِ S بگذاریم، پاداش: sum_{u in S\\{v}} Bw[v,u]\n",
        "    add_gain = np.zeros((m, N), dtype=float)\n",
        "    for v in range(m):\n",
        "        for mask in range(N):\n",
        "            # مجموع وزن از هر u که در mask است به v (یعنی u قبل و v آخر)\n",
        "            s = 0.0\n",
        "            u = mask\n",
        "            while u:\n",
        "                lsb = u & -u\n",
        "                idx = (lsb.bit_length() - 1)\n",
        "                s += Bw[v, idx]\n",
        "                u ^= lsb\n",
        "            add_gain[v, mask] = s\n",
        "\n",
        "    for mask in range(N):\n",
        "        # اگر S=mask؛ v را به عنوان آخرین عضو اضافه کنیم\n",
        "        # یعنی v باید در S باشد\n",
        "        subset = mask\n",
        "        while subset:\n",
        "            lsb = subset & -subset\n",
        "            v = (lsb.bit_length() - 1)\n",
        "            prev = mask ^ lsb\n",
        "            cand = dp[prev] + add_gain[v, prev]\n",
        "            if cand > dp[mask]:\n",
        "                dp[mask] = cand\n",
        "                parent[mask, v] = 1\n",
        "            subset ^= lsb\n",
        "\n",
        "    # بازسازی ترتیب (از آخر به اول)\n",
        "    order_rev = []\n",
        "    mask = N - 1\n",
        "    while mask:\n",
        "        # پیدا کردن v ای که parent[mask, v] == 1\n",
        "        v = int(np.where(parent[mask] == 1)[0][0])\n",
        "        order_rev.append(v)\n",
        "        mask ^= (1 << v)\n",
        "    order = list(reversed(order_rev))\n",
        "    return order\n",
        "\n",
        "def spectral_init_order(Bw):\n",
        "    \"\"\"\n",
        "    ترتیب اولیه‌ی طیفی برای m بزرگ: با استفاده از مقدارویژه‌ی بردار چپ-راست\n",
        "    \"\"\"\n",
        "    m = Bw.shape[0]\n",
        "    # ماتریس جهت‌دار را به ماتریس امتیاز خالص تبدیل می‌کنیم: score[j] = out_w(j) - in_w(j)\n",
        "    out_w = np.sum(Bw, axis=0)  # وزن خروجی از هر j به دیگران: sum_i Bw[i,j]\n",
        "    in_w  = np.sum(Bw, axis=1)  # وزن ورودی به هر i از دیگران: sum_j Bw[i,j]\n",
        "    score = out_w - in_w\n",
        "    return list(np.argsort(-score))  # بیشترین امتیاز جلوتر\n",
        "\n",
        "def refine_order_2opt(order, Bw, iters=200):\n",
        "    \"\"\"\n",
        "    بهبود محلی 2-opt روی تابع هدفِ 'مجموع وزن یال‌های هم‌سو با ترتیب'\n",
        "    \"\"\"\n",
        "    m = len(order)\n",
        "    pos = {v:i for i,v in enumerate(order)}\n",
        "    def forward_weight():\n",
        "        w = 0.0\n",
        "        for i in range(m):\n",
        "            vi = order[i]\n",
        "            for j in range(i+1, m):\n",
        "                vj = order[j]\n",
        "                w += Bw[vj, vi]  # vi -> vj یعنی Bw[vj,vi]\n",
        "        return w\n",
        "\n",
        "    best = forward_weight()\n",
        "    improved = True\n",
        "    cnt = 0\n",
        "    while improved and cnt < iters:\n",
        "        improved = False\n",
        "        cnt += 1\n",
        "        for a in range(m-1):\n",
        "            for b in range(a+1, m):\n",
        "                # swap order[a], order[b] و ارزیابی سریع\n",
        "                order[a], order[b] = order[b], order[a]\n",
        "                val = forward_weight()\n",
        "                if val > best + 1e-12:\n",
        "                    best = val\n",
        "                    improved = True\n",
        "                else:\n",
        "                    order[a], order[b] = order[b], order[a]\n",
        "            if improved:\n",
        "                break\n",
        "    return order\n",
        "\n",
        "def find_dag_order(B, use_prob=None):\n",
        "    \"\"\"\n",
        "    ترتیب قابل دفاع برای DAG:\n",
        "    - وزن‌ها = |B| (و در صورت وجود، با احتمالات بوت‌استرپ ضرب می‌شود)\n",
        "    - اگر m<=20: حل دقیق DP؛ وگرنه: طیفی + 2-opt\n",
        "    \"\"\"\n",
        "    W = np.abs(B).astype(float)\n",
        "    if use_prob is not None:\n",
        "        W = W * use_prob  # اطلاعات پایداری را هم دخیل می‌کنیم\n",
        "    np.fill_diagonal(W, 0.0)\n",
        "    m = B.shape[0]\n",
        "    if m <= 20:\n",
        "        order = optimal_topo_order_by_dp(W)\n",
        "    else:\n",
        "        order = spectral_init_order(W)\n",
        "        order = refine_order_2opt(order, W, iters=300)\n",
        "    return order\n",
        "\n",
        "def project_B_to_dag(B, order):\n",
        "    \"\"\"\n",
        "    هر یالی که ترتیب را نقض کند صفر می‌کنیم تا DAG شود.\n",
        "    در B[i,j] یالِ j->i است. باید pos[j] < pos[i] باشد.\n",
        "    \"\"\"\n",
        "    Bp = B.copy()\n",
        "    pos = {v:i for i,v in enumerate(order)}\n",
        "    m = B.shape[0]\n",
        "    for i in range(m):\n",
        "        for j in range(m):\n",
        "            if i == j:\n",
        "                Bp[i,j] = 0.0\n",
        "                continue\n",
        "            if not (pos[j] < pos[i]):\n",
        "                Bp[i,j] = 0.0\n",
        "    np.fill_diagonal(Bp, 0.0)\n",
        "    return Bp\n",
        "\n",
        "\n",
        "def prune_B_advanced(B_median, B_prob=None, tau=0.1, keep_prob=0.6):\n",
        "    \"\"\"\n",
        "    هرس B با آستانه و احتمال و سپس پروجکشن به DAG طبق ترتیبِ بهینه (غیرحریصانه).\n",
        "    \"\"\"\n",
        "    B = B_median.copy()\n",
        "    # آستانه‌ی نرم\n",
        "    B[np.abs(B) < tau] = 0.0\n",
        "    # فیلتر پایداری بوت‌استرپ\n",
        "    if B_prob is not None:\n",
        "        B[B_prob < keep_prob] = 0.0\n",
        "    # ترتیب غیرحریصانه\n",
        "    order = find_dag_order(B, use_prob=B_prob)\n",
        "    # پروجکشن به DAG\n",
        "    B = project_B_to_dag(B, order)\n",
        "    return B, order\n",
        "\n",
        "def prune_A_advanced_with_order(A_median, B_order, A_prob=None,\n",
        "                                tau=0.1, keep_prob=0.6, r_min=2,\n",
        "                                soft_threshold=False, soft_lambda=0.6):\n",
        "\n",
        "\n",
        "    A = A_median.copy().astype(float)\n",
        "    m, k = A.shape\n",
        "\n",
        "    # تبدیل B_order به دیکشنری موقعیتی\n",
        "    B_order = np.array(B_order)\n",
        "    pos = {node: idx for idx, node in enumerate(B_order)}\n",
        "\n",
        "    # 1) آستانهٔ سخت/نرم بر اساس قدرمطلق\n",
        "    if soft_threshold:\n",
        "        # soft-thresholding: shrink مقادیر کوچکتر از tau\n",
        "        small_mask = np.abs(A) < tau\n",
        "        A[small_mask] *= (1.0 - soft_lambda)  # shrink them\n",
        "    else:\n",
        "        A[np.abs(A) < tau] = 0.0\n",
        "\n",
        "    # 2) فیلتر پایداری\n",
        "    if A_prob is not None:\n",
        "        lowprob = (A_prob < keep_prob)\n",
        "        A[lowprob] = 0.0\n",
        "\n",
        "    # 3) اعمال محدودیت های موقعیتی و تضمین r_min برای هر latent (ستون)\n",
        "    nodes = np.arange(m)\n",
        "    for j in range(k):\n",
        "        # تعیین threshold_pos برای این ستون j به شکلی یکنواخت روی مشاهده‌شده‌ها\n",
        "        # روش پیشنهادی: تقسیم مشاهده‌شده‌ها به k بخش و اجازه به بخش اول j+1\n",
        "        if k >= m:\n",
        "            threshold_pos = min(j, m-1)\n",
        "        else:\n",
        "            threshold_pos = int(np.floor((j+1) * m / float(k))) - 1\n",
        "            threshold_pos = max(0, min(threshold_pos, m-1))\n",
        "\n",
        "        # allowed nodes: آنهایی که position <= threshold_pos\n",
        "        allowed_nodes = np.array([node for node in nodes if pos[node] <= threshold_pos], dtype=int)\n",
        "        if allowed_nodes.size == 0:\n",
        "            # اگر هیچ نودی مجاز نبود، اجازه بده همه باشند (fallback)\n",
        "            allowed_nodes = nodes.copy()\n",
        "\n",
        "        # صفر کردن/غیرفعال کردن گره‌های غیرمجاز\n",
        "        mask_non_allowed = np.ones(m, dtype=bool)\n",
        "        mask_non_allowed[allowed_nodes] = False\n",
        "        A[mask_non_allowed, j] = 0.0\n",
        "\n",
        "        # اگر تعداد غیرصفر کمتر از r_min است، بهترین نامزدها را از allowed_nodes بازگردان\n",
        "        nz_idx = np.flatnonzero(np.abs(A[:, j]) > 0)\n",
        "        need = r_min - len(nz_idx)\n",
        "        if need > 0:\n",
        "            # کاندیدها: allowed و فعلاً صفر\n",
        "            zero_idx_allowed = np.intersect1d(np.where(A[:, j] == 0.0)[0], allowed_nodes, assume_unique=True)\n",
        "            if zero_idx_allowed.size > 0:\n",
        "                # امتیازدهی: ترکیب A_prob (اگر موجود) و قدرمطلق A_median\n",
        "                if A_prob is not None:\n",
        "                    score = (1e6 * (A_prob[:, j])) + np.abs(A_median[:, j])\n",
        "                else:\n",
        "                    score = np.abs(A_median[:, j])\n",
        "                cand_sorted = zero_idx_allowed[np.argsort(-score[zero_idx_allowed])]\n",
        "                pick = cand_sorted[:need]\n",
        "                # مقدارِ بازگردانده را حداقل tau یا مقدار میانه قرار بده\n",
        "                for idx in pick:\n",
        "                    val = A_median[idx, j]\n",
        "                    if np.abs(val) < tau:\n",
        "                        val = np.sign(val) * tau\n",
        "                    A[idx, j] = val\n",
        "\n",
        "    return A\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prune_A_with_min_nonzero(A_median, r_min=2, tau=0.1):\n",
        "    \"\"\"\n",
        "    هرس A فقط با شرط حداقل r_min (پیش‌فرض=2) عنصر غیرصفر در هر ستون.\n",
        "    \"\"\"\n",
        "    A = A_median.copy().astype(float)\n",
        "    m, k = A.shape\n",
        "\n",
        "    for j in range(k):\n",
        "        nz_idx = np.flatnonzero(np.abs(A[:, j]) > 0)\n",
        "        need = r_min - len(nz_idx)\n",
        "\n",
        "        if need > 0:\n",
        "            # ستون خیلی کم غیرصفر دارد → اضافه کن\n",
        "            zero_idx = np.where(A[:, j] == 0)[0]\n",
        "            if zero_idx.size > 0:\n",
        "                cand = zero_idx[:need]  # ساده: اولین‌ها\n",
        "                for idx in cand:\n",
        "                    sgn = 1.0 if A_median[idx, j] >= 0 else -1.0\n",
        "                    if sgn == 0: sgn = 1.0\n",
        "                    A[idx, j] = sgn * tau  # مقدار کوچک غیرصفر\n",
        "    return A\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Graphviz DOT writer & render PNG\n",
        "# ---------------------------\n",
        "def graph_to_dot_png(B, A, title, filename_png, var_prefix_obs='x', var_prefix_lat='h'):\n",
        "    \"\"\"\n",
        "    Produce a DOT file and render with 'dot' to PNG.\n",
        "    B: m x m or None\n",
        "    A: m x k\n",
        "    \"\"\"\n",
        "    m, k = A.shape\n",
        "    lines = []\n",
        "    lines.append('digraph G {')\n",
        "    lines.append('  graph [rankdir=TB, splines=true];')\n",
        "    lines.append('  node [shape=circle, style=filled, fontsize=10];')\n",
        "    # latents cluster top\n",
        "    lines.append('  { rank = same;')\n",
        "    for j in range(k):\n",
        "        name = f'{var_prefix_lat}{j+1}'\n",
        "        lines.append(f'    \"{name}\" [fillcolor=\"#FFCC80\", style=\"dashed,filled\"];')\n",
        "    lines.append('  }')\n",
        "    # observed cluster bottom\n",
        "    lines.append('  { rank = same;')\n",
        "    for i in range(m):\n",
        "        name = f'{var_prefix_obs}{i+1}'\n",
        "        lines.append(f'    \"{name}\" [fillcolor=\"#AECBFA\"];')\n",
        "    lines.append('  }')\n",
        "    # latent -> observed\n",
        "    for i in range(m):\n",
        "        for j in range(k):\n",
        "            w = float(A[i, j])\n",
        "            if abs(w) < 1e-12: continue\n",
        "            pen = 1.0 + min(3.0, abs(w)*3.0)\n",
        "            style = 'dashed' if abs(w) < 0.12 else 'solid'\n",
        "            color = 'red' if w < 0 else 'black'\n",
        "            lines.append(f'  \"{var_prefix_lat}{j+1}\" -> \"{var_prefix_obs}{i+1}\" [label=\"{w:.2f}\", color=\"{color}\", style=\"{style}\", penwidth={pen}];')\n",
        "    # observed -> observed\n",
        "    if B is not None:\n",
        "        for i in range(m):\n",
        "            for j in range(m):\n",
        "                if i == j: continue\n",
        "                w = float(B[i, j])\n",
        "                if abs(w) < 1e-12: continue\n",
        "                pen = 1.0 + min(3.0, abs(w)*3.0)\n",
        "                style = 'dashed' if abs(w) < 0.12 else 'solid'\n",
        "                color = 'red' if w < 0 else 'black'\n",
        "                lines.append(f'  \"{var_prefix_obs}{j+1}\" -> \"{var_prefix_obs}{i+1}\" [label=\"{w:.2f}\", color=\"{color}\", style=\"{style}\", penwidth={pen}];')\n",
        "    lines.append(f'  labelloc=\"t\"; label=\"{title}\"; fontsize=14;')\n",
        "    lines.append('}')\n",
        "    dot_text = \"\\n\".join(lines)\n",
        "    dotfile = filename_png + \".dot\"\n",
        "    with open(dotfile, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(dot_text)\n",
        "    # render\n",
        "    try:\n",
        "        subprocess.check_call([\"dot\", \"-Tpng\", dotfile, \"-o\", filename_png])\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Graphviz dot rendering failed: {e}\\nMake sure 'dot' (graphviz) is installed.\")\n",
        "\n",
        "\n",
        "#----------------------------\n",
        "# 10) Perecision- Recall\n",
        "#----------------------------\n",
        "\n",
        "def precision_recall(Mat_true, Mat_est):\n",
        "    # Mat_true, Mat_est: صفر/غیرصفر\n",
        "    Mat_true_bin = (Mat_true != 0).astype(int)\n",
        "    Mat_est_bin = (Mat_est != 0).astype(int)\n",
        "    tp = np.sum((Mat_true_bin==1) & (Mat_est_bin==1))\n",
        "    fp = np.sum((Mat_true_bin==0) & (Mat_est_bin==1))\n",
        "    fn = np.sum((Mat_true_bin==1) & (Mat_est_bin==0))\n",
        "    prec = tp / (tp + fp + 1e-12)\n",
        "    rec  = tp / (tp + fn + 1e-12)\n",
        "    return prec, rec\n",
        "\n",
        "# ---------------------------\n",
        "# 12) full advanced pipeline\n",
        "# ---------------------------\n",
        "def run_pipeline_advanced(B_manual, M_manual, config: RunConfig):\n",
        "    os.makedirs(config.outdir, exist_ok=True)\n",
        "    m, k_true = M_manual.shape\n",
        "    assert B_manual.shape == (m, m), \"B must be (m x m)\"\n",
        "    rng = np.random.default_rng(config.scm.seed)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    # 1) generate data\n",
        "    print(\"Generating data...\")\n",
        "\n",
        "    X, Q_true, H=generate_data(B_manual, M_manual, n=config.n, sigma2=config.scm.sigma2, seed=config.scm.seed,\n",
        "                mog_config=config.mog)\n",
        "\n",
        "    A_true = np.linalg.inv(np.eye(m) - B_manual) @ M_manual  # effective latent->observed mixing seen in X\n",
        "    print(\"A_true:\\n\",A_true)\n",
        "\n",
        "    # 2) bootstrap stability (estimate A and B many times)\n",
        "    print(f\"Bootstrap stability: repeats={config.boot.repeats}, k_est={config.ifa.k_est} ...\")\n",
        "    A_prob, A_median, B_prob, B_median = bootstrap_stability(X, k_est=config.ifa.k_est,\n",
        "                                                             repeats=config.boot.repeats,\n",
        "                                                             tau_A=config.boot.tau_A, tau_B=config.boot.tau_B,\n",
        "                                                          seed=config.scm.seed,sigma2=config.scm.sigma2,alpha_B=5e-2)\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    #3) purning A,B\n",
        "\n",
        "    # b)purning B\n",
        "    print(\"B_median_Before\\n\",B_median)\n",
        "    print(\"Pruning B...\")\n",
        "    B_pruned, order_B = prune_B_advanced(B_median, B_prob=B_prob, tau=config.boot.tau_B, keep_prob=config.boot.keep_prob)\n",
        "    print(\"B_median_After prun :\\n\",B_median)\n",
        "\n",
        "    # b)purning A\n",
        "    print(\"A_median_Before\\n\",A_median)\n",
        "    print(\"Pruning A...\")\n",
        "    print(\"B_order :\\n\",order_B)\n",
        "    A_pruned =prune_A_advanced_with_order(A_median, B_order=order_B, A_prob=A_prob, tau=config.boot.tau_A, keep_prob=config.boot.keep_prob, r_min=2)\n",
        "\n",
        "    print(\"A_median_After prun:\\n\",A_median)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    # 4) align A_median (k_est -> k_true) via CF alignment\n",
        "    print(\"Aligning estimated factors to true factors using CF...\")\n",
        "    try:\n",
        "        S_est_full = np.linalg.pinv(A_pruned) @ X  # k_est x n\n",
        "        perm, signs = cf_alignment(Q_true, S_est_full, tgrid=np.linspace(-3,3,121))\n",
        "\n",
        "        # ساخت A_aligned و M_aligned\n",
        "        k_true = Q_true.shape[0]\n",
        "        m = A_pruned.shape[0]\n",
        "\n",
        "        A_aligned = np.zeros((m, k_true))\n",
        "\n",
        "\n",
        "        for i in range(k_true):\n",
        "            j = perm[i]\n",
        "            A_aligned[:, i] = signs[i] * A_pruned[:, j]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"CF alignment failed:\", e)\n",
        "        # fallback: cosine + Hungarian\n",
        "        from scipy.optimize import linear_sum_assignment\n",
        "        A_est_n = normalize_cols(A_pruned)\n",
        "        A_true_n = normalize_cols(A_true)\n",
        "        C = 1 - (A_true_n.T @ A_est_n)\n",
        "        row, col = linear_sum_assignment(C)\n",
        "        k_true = A_true.shape[1]\n",
        "        A_aligned = np.zeros((m, k_true))\n",
        "\n",
        "        for i,j in zip(row, col):\n",
        "            if i < k_true and j < A_pruned.shape[1]:\n",
        "                sgn = np.sign((A_true[:, i] * A_pruned[:, j]).sum())\n",
        "                A_aligned[:, i] = sgn * A_pruned[:, j]\n",
        "\n",
        "    print(\"A_alined:\\n\",A_aligned)\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    # 4) apply stability filtering: keep entries in A_aligned where magnitude > tau_A\n",
        "\n",
        "    print(\"Applying stability filtering A...\")\n",
        "\n",
        "\n",
        "    # a) فیلتر بر اساس احتمال بوت‌استرپ\n",
        "\n",
        "    A_prob_aligned = A_prob[:, perm] if 'perm' in locals() and perm is not None else A_prob\n",
        "    A_final = A_aligned.copy()\n",
        "\n",
        "    if A_prob_aligned is not None:\n",
        "        lowprob_mask = (A_prob_aligned < config.boot.keep_prob)\n",
        "        A_final[lowprob_mask] = 0.0\n",
        "\n",
        "    # b) آستانه بر اساس قدرمطلق\n",
        "    A_final[np.abs(A_final) < config.boot.tau_A ] = 0.0\n",
        "\n",
        "    print(\"A_final:\\n\", A_final)\n",
        "\n",
        "\n",
        "    print(\"Applying stability filtering to B...\")\n",
        "\n",
        "    # a) فیلتر بر اساس احتمال بوت‌استرپ\n",
        "    B_final = B_pruned.copy()\n",
        "    B_final[B_prob < config.boot.keep_prob] = 0.0\n",
        "\n",
        "   # b) آستانه بر اساس قدرمطلق\n",
        "    B_final[np.abs(B_final) < config.boot.tau_B ] = 0.0\n",
        "\n",
        "\n",
        "    np.fill_diagonal(B_final, 0.0)\n",
        "\n",
        "    print(\"B_final:\\n\",B_final)\n",
        "\n",
        "\n",
        "\n",
        " #-------------------------------------------------------------------------------------------------------------------------\n",
        "    # 5) compute S_est for final A selection (for reconstruction)\n",
        "    print(\"compute S_est for final A selection (for reconstruction)...\")\n",
        "    # select corresponding est columns used in alignment (perm), reconstruct S_est_sel\n",
        "    # if perm is available:\n",
        "    try:\n",
        "        k_est = config.ifa.k_est\n",
        "        if 'perm' in locals() and perm is not None:\n",
        "            # S_est_full computed earlier\n",
        "            S_sel = np.zeros((k_true, X.shape[1]))\n",
        "            for i in range(k_true):\n",
        "                j = perm[i]\n",
        "                S_sel[i, :] = signs[i] * S_est_full[j, :]\n",
        "        else:\n",
        "            # fallback: least-squares S_sel = pinv(A_final) X\n",
        "            S_sel = np.linalg.pinv(A_final) @ X\n",
        "    except Exception:\n",
        "        S_sel = np.linalg.pinv(A_final) @ X\n",
        "\n",
        "    print(\"S_sel : \\n\",S_sel)\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # 6) metrics\n",
        "    print(\"Computing metrics...\")\n",
        "\n",
        "    # a) Precision-Recall\n",
        "    prec_B, rec_B = precision_recall(B_manual, B_final)\n",
        "    prec_A, rec_A = precision_recall(A_true, A_final)\n",
        "\n",
        "    # b) CF distance  True latent vs estimate latent\n",
        "    cf_dist = cf_distance(Q_true, S_sel, m_grid=200, seed=config.scm.seed)\n",
        "\n",
        "    # c) Reconstruction error\n",
        "    recon_err = np.linalg.norm(X - A_final @ S_sel, 'fro') / np.linalg.norm(X, 'fro')\n",
        "\n",
        "\n",
        "    print(f\"Precision B: {prec_B:.3f}, Recall B: {rec_B:.3f}\")\n",
        "    print(f\"Precision A: {prec_A:.3f}, Recall A: {rec_A:.3f}\")\n",
        "    print(f\"Reconstruction Error: {recon_err:.4f}\")\n",
        "    print(f\"CF Distance: {cf_dist:.6f}\")\n",
        "\n",
        "    # 7) render graphs with graphviz to PNG\n",
        "    png_true = os.path.join(config.outdir, \"true_graph.png\")\n",
        "    png_est = os.path.join(config.outdir, \"est_graph.png\")\n",
        "\n",
        "    print(\"Rendering graphs (requires 'dot' from graphviz)...\")\n",
        "    try:\n",
        "        graph_to_dot_png(B_manual, M_manual, \"True model (H M & B)\", png_true)\n",
        "        graph_to_dot_png(B_final, A_final, \"Estimated (bootstrap-stable) model\", png_est)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Graphviz render failed:\", e)\n",
        "        # fallback: save textual dot files for inspection\n",
        "\n",
        "    # 8) show PNGs side-by-side (if produced)\n",
        "    try:\n",
        "        img1 = plt.imread(png_true)\n",
        "        img2 = plt.imread(png_est)\n",
        "        fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
        "        axes[0].imshow(img1); axes[0].axis('off'); axes[0].set_title(\"True model\")\n",
        "        axes[1].imshow(img2); axes[1].axis('off'); axes[1].set_title(\"Estimated model\")\n",
        "\n",
        "        # ذخیره نمودار مقایسه‌ای\n",
        "        comparison_name = config.senario+\"_model_comparison\"+\".png\"\n",
        "        plt.savefig(comparison_name, bbox_inches='tight', dpi=300)\n",
        "        print(f\"Comparison plot saved as: {comparison_name}\")\n",
        "\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"Show PNGs failed (maybe dot did not produce images):\", e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 10) save JSON results\n",
        "    out = {\n",
        "        \"precision_B\": float(prec_B),\n",
        "        \"recall_B\": float(rec_B),\n",
        "        \"precision_A\": float(prec_A),\n",
        "        \"recall_A\": float(rec_A),\n",
        "        \"reconstruction_error\": float(recon_err),\n",
        "        \"cf_distance\": float(cf_dist),\n",
        "        \"B_true\": B_manual.tolist(),\n",
        "        \"M_true\": M_manual.tolist(),\n",
        "\n",
        "        \"A_final\": A_final.tolist(),\n",
        "        \"B_final\": B_final.tolist(),\n",
        "        \"A_prob\": A_prob.tolist(),\n",
        "        \"B_prob\": B_prob.tolist(),\n",
        "        \"perm\": perm.tolist() if 'perm' in locals() and perm is not None else None,\n",
        "        \"signs\": signs.tolist() if 'signs' in locals() and signs is not None else None\n",
        "    }\n",
        "    with open(os.path.join(config.outdir, \"results_advanced_cf.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(out, f, indent=2)\n",
        "    print(\"Saved results to\", os.path.join(config.outdir, \"results_advanced_cf.json\"))\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Example: use your matrices (replace with larger examples if desired)\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    res=run_comprehensive_data_tests()\n",
        "    print(res)\n",
        "\n",
        "    '''\n",
        "    B_manual = np.array([\n",
        "    [0.0, 1.0, 0.0],\n",
        "    [0.0, 0.0, 1.0],\n",
        "    [0.0, 0.0, 0.0]\n",
        "    ], dtype=float)\n",
        "\n",
        "    M_manual = np.array([\n",
        "    [1.0, 0.0],\n",
        "    [0.0, 0.0],\n",
        "    [0.0, 1.0]\n",
        "    ], dtype=float)\n",
        "\n",
        "    cfg = RunConfig(\n",
        "      n=20000,\n",
        "      scm = SCMConfig(B=B_manual, M=M_manual, sigma2=4.3, seed=42),\n",
        "      mog = MOGConfig(n_components=2, means_strategy=\"spread\",variance_strategy=\"low\",weights_strategy=\"balanced\"),\n",
        "      ifa = IFAConfig(k_est=3, max_iter=500, tol=1e-7, reg_latent=5e-3),\n",
        "      boot = BootstrapConfig(repeats=20, tau_A=0.2, tau_B=0.1, keep_prob=0.6),\n",
        "      senario=\"Default\",\n",
        "      outdir=\"./ifa_cf_results_strong\",\n",
        "      use_graphviz=True\n",
        "       )\n",
        "\n",
        "\n",
        "    res = run_pipeline_advanced(B_manual, M_manual, cfg)\n",
        "    print(res)\n",
        "    '''\n",
        "\n",
        "    #----------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}